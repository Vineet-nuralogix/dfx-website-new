"use strict";(self.webpackChunkdfx_website=self.webpackChunkdfx_website||[]).push([[9482],{8308:(e,a,n)=>{n.r(a),n.d(a,{default:()=>s});var t=n(7294),r=n(2263),o=n(7254),i=n(1207),l=n(6010);function s(){const{siteConfig:e}=(0,r.Z)();return t.createElement(o.Z,{title:`${e.title}`,description:"Description will go into a meta tag in <head />"},t.createElement("header",{className:(0,l.Z)("hero hero--primary",i.Z.sdkBanner)}),t.createElement("main",null,t.createElement("body",null,t.createElement("div",null,t.createElement("div",{className:i.Z.text_center},t.createElement("h1",null,"DeepAffex\u2122 SDK"),t.createElement("div",{className:i.Z.paraCenter},t.createElement("p",null,"The primary purpose of the SDK is to convert an incoming stream of face-tracked image data into resultant blood-flow. This procedure is referred to as the blood-flow extraction and is an important stage in the TOI \u201cfront-end\u201d pipeline functionality required for DeepAffex\u2122 processing. Through configuration, the SDK is used to generate measurement data (binary payloads) sequences that are then forwarded to DeepAffex\u2122 for analysis and processing."),t.createElement("p",null,"The SDK provides extraction of the subject's facial blood-flow information from the incoming video frames. The client application is responsible for supplying video frames with accurate timestamps (e.g. from a digital camera or video file), detecting faces in the video frames and annotating them with \u201cMPEG-4 facial animation points\u201d (a standard naming convention for face point labeling provided by many 3rd party off-the-shelf face-detection libraries e.g. dlib, Visage etc.)."),t.createElement("p",null,"For more information, please ",t.createElement("b",null,t.createElement("a",{href:"/contact"},"contact us."))),t.createElement("br",null)))))))}},1207:(e,a,n)=>{n.d(a,{Z:()=>t});const t={heroBanner:"heroBanner_qdFl",buttons:"buttons_AeoN",animation:"animation_TdOs",animation_frame:"animation_frame__iKW",text_center:"text_center_sBZP",disclaimer:"disclaimer_piVT",small_img:"small_img_JkXM",closePopup:"closePopup_UonM",closePopupShow:"closePopupShow_c6o_",fadeIn:"fadeIn_sitH",popup:"popup_CV0c",popuptext:"popuptext_ZIWU",show:"show_EDYt",videoframe:"videoframe_vM9w",headerContainer:"headerContainer_Dcc3",contactform:"contactform_t77k",tableCenter:"tableCenter_wv0r",downloadsBanner:"downloadsBanner_DXii",contactBanner:"contactBanner_BcmO",apiBanner:"apiBanner_ilEW",sdkBanner:"sdkBanner_P9Rc",wmsBanner:"wmsBanner_fJCm",paraCenter:"paraCenter_MRZ0",subTagline:"subTagline_eUY1"}}}]);